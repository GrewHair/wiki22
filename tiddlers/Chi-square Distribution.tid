.att.cdf: $$\displaystyle \frac 1 {\Gamma(k/2)}x^{k/2-1}e{-x/2}
.att.cf: $$\displaystyle \left(1 - 2it \right)^{-k/2}$$
.att.entropy: $$\displaystyle \frac k 2 + \ln \left(2\Gamma \left( \frac k 2 \right)\right) + \left(1 - \frac k 2\right)\psi\left(\frac k 2\right)$$
.att.fisher_info: 
.att.kullback-leibler: 
.att.kurtosis: $$\displaystyle \frac {12} k$$
.att.mad: 
.att.mean: $$k$$
.att.median: $$\displaystyle \approx k \left(1 - \frac 2 {9k} \right)^3$$
.att.mgf: $$\displaystyle \left(1-2t\right)^{-k/2}$$ for $$\displaystyle t < \frac 1 2$$
.att.mode: $$\max(k - 2, 0)$$
.att.notation: $$\chi^2(k)$$ or $$\chi_k^2$$
.att.parameters: $$k \in \mathbb N^*$$ ("[[degrees of freedom|Degrees of Freedom]]")
.att.pdf: $$\displaystyle \frac 1 {2^{k/2}\Gamma(k/2)} x^{k/2-1}e^{-x/2}$$
.att.pgf: $$\displaystyle \left( 1 - 2\ln t \right)^{-k/2}$$ for $$0 < t < \sqrt{e}$$
.att.pmf: 
.att.quantile: 
.att.skewness: $$\displaystyle \sqrt{8/k}$$
.att.support: $$x \in (0, +\infty)$$ if $$k=1$$, otherwise x \in [0, +\infty)
.att.variance: $$2k$$
.hsk.tagged_diagram: [<currentTiddler>tags[]field:icon[_my/images/icons/diagram]]
.hsk.tagged_exemplar: [<currentTiddler>tags[]field:icon[_my/images/icons/exemplar]]
.hsk.tagged_feature: [<currentTiddler>tags[]field:icon[_my/images/icons/feature]]
.hsk.tagged_topic: [<currentTiddler>tags[]field:icon[_my/images/icons/topic]]
.hsk.transcludes: [[_my/images/png/chi-square_pdf]][[_my/images/png/chi-square_cdf]]
created: 20200815083928265
modified: 20200815130444510
tags: [[Probability Distribution]] [[Probability Theory]] [[Машинное обучение и анализ данных (Яndex, МФТИ)]]
title: Chi-square Distribution
tmap.id: f6b84efe-608f-407b-a397-2652bd453a11
type: text/vnd.tiddlywiki

''AKA Helmert Distribution''

[[Summary|Chi-square Distribution/Summary]]

Assume there is $$k$$ [[i.i.d.|Independent and Identically Distributed]] [[Standard Normal|Standard Normal Distribution]] [[Random Variables|Random Variable]]:

$$
X_1, X_2, \ldots, X_k \sim N(0,1).
$$

Let's define a new [[Random Variable]] $$X$$:

$$
\displaystyle
X = \sum_{i=1}^k X_i^2 \;\sim\; \chi_k^2.
$$

The distribution of such a [[Random Variable]] is [[Chi-square|Chi-square Distribution]] with $$k$$ [[Degrees of Freedom]].

Its [[PDF|Probability Density Function]] and [[CDF|Cumulative Distribution Function]] for different values of $$k$$ look like this:

|{{_my/images/png/chi-square_pdf}}|{{_my/images/png/chi-square_cdf}}|

Just by visual inspection one may notice the following:

* The [[PDF|Probability Density Function]] is nonnegative - because squares are!
* When there are only one or two [[RV|Random Variable]]s to sum (i.e. the [[Degrees of Freedom]] are 1 or 2), the [[Mode]] of this distribution is equal to $$0$$ - it is intuitive for the case when $$k=1$$, because the [[Mode]] of a [[Standard Normal|Standard Normal Distribution]] [[RV|Random Variable]] is $$0$$
** From these two bullet points it follows that for $$k=1$$ and $$k=2$$ the [[PDF|Probability Density Function]] is [[Monotonically Decreasing|Monotonic Function]]
* As $$k$$ grows, the [[Mode]](/maximum) of the [[PDF|Probability Density Function]] increases - this again is intuitive, because as number of [[Standard Normal|Standard Normal Distribution]] [[RV|Random Variable]]s increases, the sum of their squares should tend to get larger and larger