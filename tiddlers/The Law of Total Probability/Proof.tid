.hsk.tagged_diagram: [<currentTiddler>tags[]field:icon[_my/images/icons/diagram]]
.hsk.tagged_exemplar: [<currentTiddler>tags[]field:icon[_my/images/icons/exemplar]]
.hsk.tagged_feature: [<currentTiddler>tags[]field:icon[_my/images/icons/feature]]
.hsk.tagged_topic: [<currentTiddler>tags[]field:icon[_my/images/icons/topic]]
created: 20200429194148284
modified: 20200429195208205
tags: [[Probability Theory]] [[All of Statistics (Larry Wasserman)]]
title: The Law of Total Probability/Proof
tmap.id: 12ec224a-4386-4603-9356-729f18696422
type: text/vnd.tiddlywiki

Define $$C_j = B \cap A_j$$ and note that $$C_1, \ldots, C_k$$ are [[Disjoint|Disjoint Sets]] and that $$B = \bigcup_{j=1}^k C_j.$$ Hence,

$$
\displaystyle
\mathbb P(B) = \sum_j \mathbb P(C_j)
            = \sum_j \mathbb P(B \cap A_j)
				    = \sum_j \mathbb P(B|A_j)\mathbb P(A_j),
$$

since $$\mathbb P(B \cap A_j) = \mathbb(B|A_j)\mathbb(A_j)$$ from the definition of [[Conditional Probability]].

$$\blacksquare$$