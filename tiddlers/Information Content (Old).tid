.hsk.tagged_diagram: [<currentTiddler>tags[]field:icon[_my/images/icons/diagram]]
.hsk.tagged_exemplar: [<currentTiddler>tags[]field:icon[_my/images/icons/exemplar]]
.hsk.tagged_feature: [<currentTiddler>tags[]field:icon[_my/images/icons/feature]]
.hsk.tagged_topic: [<currentTiddler>tags[]field:icon[_my/images/icons/topic]]
created: 20200304185459476
modified: 20200325163928008
tags: Stub [[Information Theory, Pattern Recognition, and Neural Networks (David MakKay, University of Cambridge)]] [[Information Theory]]
title: Information Content (Old)
tmap.id: 25c4cf0f-444c-43b4-ba0e-dfa04d7e09c6
type: text/vnd.tiddlywiki

$$
\displaystyle I_X(x) \equiv 
- \log_2[p_X(x)] = 
\log_2\left(\frac 1{p_X(x)}\right)
$$

* [[Information Content]] is additive for independent random variables
*>E.g.