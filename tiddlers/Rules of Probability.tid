.hsk.tagged_diagram: [<currentTiddler>tags[]field:icon[_my/images/icons/diagram]]
.hsk.tagged_exemplar: [<currentTiddler>tags[]field:icon[_my/images/icons/exemplar]]
.hsk.tagged_feature: [<currentTiddler>tags[]field:icon[_my/images/icons/feature]]
.hsk.tagged_topic: [<currentTiddler>tags[]field:icon[_my/images/icons/topic]]
created: 20200303173736394
modified: 20200325171722448
tags: [[Information Theory, Pattern Recognition, and Neural Networks (David MakKay, University of Cambridge)]] [[Probability Theory]]
title: Rules of Probability
tmap.id: dc262080-18ab-4e42-b010-ae33e071facf
type: text/vnd.tiddlywiki

* Product Rule
*>$$P(s,r)=P(s)P(r|s)=P(r)P(s|r)$$
* Sum Rule
*>$$P(r)=\sum_sP(s,r)$$

Where

$$P(s,r)$$ is joint probability;

$$P(s),\ P(r)$$ are marginal probabilities;

$$P(s|r),\ P(r|s)$$ are conditional probabilities.

Thus,

$$\displaystyle P(s|r)=\frac{P(r|s)P(s)}{P(r)}=\frac{P(r|s)P(s)}{\sum_sP(s,r)}$$ - posterior probability of s