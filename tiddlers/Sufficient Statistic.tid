.hsk.tagged_diagram: [<currentTiddler>tags[]field:icon[_my/images/icons/diagram]]
.hsk.tagged_exemplar: [<currentTiddler>tags[]field:icon[_my/images/icons/exemplar]]
.hsk.tagged_feature: [<currentTiddler>tags[]field:icon[_my/images/icons/feature]]
.hsk.tagged_topic: [<currentTiddler>tags[]field:icon[_my/images/icons/topic]]
created: 20200228194906703
modified: 20200828094007829
tags: Statistics
title: Sufficient Statistic
tmap.id: 0e70a219-2fa7-41f2-90b3-c199f72ff17c
type: text/vnd.tiddlywiki

A [[Statistic]] is [[Sufficient|Sufficient Statistic]] if it conveys all the available information about the [[parameter|Statistical Parameter]].

More formally (from Wikipedia), a [[Statistic]] $$T(X)$$ is [[Sufficient|Sufficient Statistic]] //for underlying [[parameter|Statistical Parameter]]// $$\theta$$ precisely if the [[Conditional Probability Distribution]] of the data $$X$$, given $$T(X)$$, does not depend on the [[Parameter|Statistical Parameter]] $$\theta$$.

Simply speaking, suppose you have a [[Sample|Statistical Sample]] and you are interested in some <<tex \theta "Statistical Parameter">>. If then you come up with a [[Sufficient Statistic]], you can then throw all the data away, because all the information you need sits in that statistic. 

When the [[Likelihood Function]] can be decomposed into two factors, one of which depends only on //y// (i.e. the [[sample|Statistical Sample]]) and another one depends on <<tex \theta "Statistical Parameter">> and some [[statistic|Statistic]] $$T(y)$$:

$$\mathcal L  (\theta;    y) = 
  c(y)
  \mathcal L^*(\theta; T(y)),
$$

then this statistic $$T(y)$$ is called [[Sufficient|Sufficient Statistic]].

Note that $$c(y)$$ here is considered just some completely irrelevant scaling constant, because:

* It doesn't depend on <<tex \theta "Statistical Parameter">>, and thus you can not solve for $$\theta$$
* The exact value of likelihood is meaningless anyway (see [[likelihood]]). 

<br>

[[Example 1|Sufficient Statistic/Example#1]]

[[Example 2|Sufficient Statistic/Example#2]]