.hsk.tagged_diagram: [<currentTiddler>tags[]field:icon[_my/images/icons/diagram]]
.hsk.tagged_exemplar: [<currentTiddler>tags[]field:icon[_my/images/icons/exemplar]]
.hsk.tagged_feature: [<currentTiddler>tags[]field:icon[_my/images/icons/feature]]
.hsk.tagged_topic: [<currentTiddler>tags[]field:icon[_my/images/icons/topic]]
created: 20200419120030010
modified: 20200419120615502
tags: Stub [[Introduction to Deep Learning With Keras (Datacamp)]]
title: Softmax
tmap.id: 7159d14a-60ba-4912-a746-e0caa4aba392
type: text/vnd.tiddlywiki

[[Softmax]] function is the main type of [[Activation Function]] to be used at the output layers of [[Neural Networks]] in [[Multiclass Classification]] problems.

It's main useful feature is that it ensures that the outputs are non-negative __''and''__ sum up to one - and thus can be interpreted as [[Probabilities|Probability]] of classes, which greatly improves the interpretability of the results.

However, [[Softmax]] can't really be used in [[Multilabel Classification]] problems, because the labels are not mutually exclusive there.